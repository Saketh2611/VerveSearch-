# -*- coding: utf-8 -*-
"""VerveSearch.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DvhD99897duHLfrzQHDjUkeYwBJTafmD
"""

!pip install -U sentence-transformers qdrant-client

from google.colab import files
uploaded = files.upload()

import pandas as pd  # üìä For handling Excel/CSV data in tabular form (DataFrame)
from sentence_transformers import SentenceTransformer  # üß† For generating sentence embeddings (NLP)
from qdrant_client import QdrantClient  # üóÉÔ∏è For connecting to the Qdrant vector database
from qdrant_client.models import VectorParams, Distance, PointStruct  # ‚öôÔ∏è Qdrant vector config and data structure
from sklearn.metrics.pairwise import cosine_similarity  # üìè For computing similarity (used in traditional ML)

df = pd.read_csv("train.csv")
df.head()
df.info()

df = df.dropna()
df

df.describe()

contexts = df["Context"].astype(str).tolist()
responses = df["Response"].astype(str).tolist()

model = SentenceTransformer("paraphrase-mpnet-base-v2")
embeddings = model.encode(contexts)

client = QdrantClient(
    url="https://23a37241-1707-4f1a-8f5e-47c00502551d.us-west-1-0.aws.cloud.qdrant.io:6333",
    api_key="eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIn0.6MHdGWXVS2dEszyAaokzSlQbqe0Fdh_vFEvBJxXH50c"
)

client.delete_collection(collection_name="sports_therapy_logs")
print("Old collection deleted.")

client.recreate_collection(
    collection_name="therapy_logs",
    vectors_config=VectorParams(size=768, distance=Distance.COSINE)
)

points = [
    PointStruct(
        id=i,
        vector=vec.tolist(),  # ‚úÖ correct keyword
        payload={
            "context": contexts[i],
            "response": responses[i]
        }
    )
    for i, vec in enumerate(embeddings)
]

from tqdm import tqdm  # Optional: for a progress bar

batch_size = 100  # You can tune this to be smaller or larger
for i in tqdm(range(0, len(points), batch_size), desc="Uploading to Qdrant"):
    batch = points[i:i + batch_size]
    client.upsert(
        collection_name="therapy_logs",
        points=batch
    )

query = "Education"

query_vector = model.encode(query)
results = client.search(collection_name="therapy_logs",query_vector=query_vector.tolist(),limit=5)

for i, result in enumerate(results, 1):
    print(f"Result {i}:")
    print(f"üß† Context: {result.payload['context']}")
    print(f"üí¨ Response: {result.payload['response']}")
    print(f"üîó Score: {result.score:.4f}")
    print("-" * 50)